{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from deep_audio import Directory, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_algo = 'melbanks'\n",
    "n_audios = 40\n",
    "n_segments = 50\n",
    "model_algo = 'lstm'\n",
    "n_rate = 24000\n",
    "\n",
    "DATASET_PATH = f'processed/{method_algo}_{n_audios}-{n_segments}_{n_rate}.json'\n",
    "\n",
    "inputs, targets, mapping = Directory.load_json_data(DATASET_PATH, inputs_fieldname=method_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_model():\n",
    "    # build the network architecture\n",
    "    model = keras.Sequential([\n",
    "        # 1st hidden layer\n",
    "        keras.layers.LSTM(512, input_shape=[inputs.shape[1], inputs.shape[2]], return_sequences=True),\n",
    "        keras.layers.LSTM(256),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        # output layer\n",
    "        keras.layers.Dense(len(mapping), activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DOS DADOS\n",
    "random_state = 42\n",
    "# for random_state in [5438, 53, 14]:\n",
    "#     for _ in range(4):\n",
    "# split data into train and test set\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs,\n",
    "                                                                          targets,\n",
    "                                                                          test_size=0.2,\n",
    "                                                                          stratify=targets,\n",
    "                                                                          random_state=random_state)\n",
    "\n",
    "inputs_train, inputs_valid, targets_train, targets_valid = train_test_split(inputs_train,\n",
    "                                                                            targets_train,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            stratify=targets_train,\n",
    "                                                                            random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVA UMA CÓPIA DOS DADOS DE TESTE\n",
    "\n",
    "# data = {\n",
    "#     \"mapping\": mapping,\n",
    "#     \"labels\": targets_test,\n",
    "#     \"mfcc\": inputs_test,\n",
    "# }\n",
    "\n",
    "# JSON.create_json_file(f'datatest/deep/datatest_{random_state}_{inputs.shape[0]}.json', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIA O MODELO\n",
    "model = create_dense_model()\n",
    "\n",
    "# COMPILA A REDE\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVA A ESTRUTURA DO MODELO\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "Directory.create_directory(f'models/{model_algo}/{method_algo}/{timestamp}')\n",
    "\n",
    "JSON.create_json_file(f'models/{model_algo}/{method_algo}/{timestamp}/model_structure.json', model.to_json())\n",
    "\n",
    "model_save_filename = f'models/{model_algo}/{method_algo}/{timestamp}/model_weight.h5'\n",
    "\n",
    "# DECIDE QUANDO PARAR\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=300, restore_best_weights=True)\n",
    "\n",
    "# SALVA OS PESOS\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINA O MODELO\n",
    "history = model.fit(inputs_train, targets_train,\n",
    "                    validation_data=(inputs_valid, targets_valid),\n",
    "                    epochs=10000,\n",
    "                    batch_size=128,\n",
    "                    callbacks=[earlystopping_cb, mdlcheckpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GERA O GRAFICO DE ACURÁCIA\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(f'models/{model_algo}/{method_algo}/{timestamp}/graph_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# GERA O GRÁFICO DE PERCA\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(f'models/{model_algo}/{method_algo}/{timestamp}/graph_loss.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEGA A MAIOR E ACURÁCIA\n",
    "higher_accuracy = model.evaluate(inputs_test, targets_test, batch_size=128)\n",
    "\n",
    "higher_accuracy = str(int(higher_accuracy[1] * 10000)).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENOMEIA A PASTA\n",
    "Directory.rename_directory(f'models/{model_algo}/{method_algo}/{timestamp}',\n",
    "                           f'models/{model_algo}/{method_algo}/acc{higher_accuracy}_seed{random_state}_epochs{len(history.history[\"accuracy\"])}_time{timestamp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3810jvsc74a57bd02db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}