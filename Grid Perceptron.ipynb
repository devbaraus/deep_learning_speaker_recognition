{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from deep_audio import Directory, JSON\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_algo = 'mfcc'\n",
    "model_algo = 'perceptron'\n",
    "n_rate = 24000\n",
    "\n",
    "DATASET_PATH = f'processed/{method_algo}/{method_algo}_{n_rate}.json'\n",
    "\n",
    "inputs, targets, mapping = Directory.load_json_data(DATASET_PATH, inputs_fieldname=method_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # build the network architecture\n",
    "    model = keras.Sequential([\n",
    "        # input layer\n",
    "        keras.layers.Flatten(input_shape=(inputs.shape[1], inputs.shape[2])),\n",
    "\n",
    "        # 1st hidden layer\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "        # 3rd hidden layer\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "        # output layer\n",
    "        keras.layers.Dense(len(mapping), activation='softmax'),\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DOS DADOS\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs,\n",
    "                                                                          targets,\n",
    "                                                                          test_size=0.2,\n",
    "                                                                          stratify=targets,\n",
    "                                                                          random_state=random_state)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                                                          y_train,\n",
    "                                                                          test_size=0.2,\n",
    "                                                                          stratify=y_train,\n",
    "                                                                          random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=build_model, epochs=2000, batch_size=128, verbose=1, )\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "grid_result = grid.fit(inputs_train, targets_train, validation_data=(inputs_valid, targets_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print best parameter after tuning\n",
    "model = grid\n",
    "best_params = model.best_params_\n",
    "sampling_rate = n_rate\n",
    "# TESTA ACCURÁCIAS\n",
    "\n",
    "score_test = model.score(X_test, y_test)\n",
    "score_valid = model.score(X_valid, y_valid)\n",
    "score_train = model.score(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# SALVA MODELO\n",
    "# filename = f'models/gridperceptron/{method_algo}_{f1_score(y_hat, y_test, average=\"macro\")}_{sampling_rate}/acc{score_test}_seed{random_state}.sav'\n",
    "\n",
    "# Directory.create_directory(filename, file=True)\n",
    "\n",
    "# joblib.dump(model, filename)\n",
    "\n",
    "# SALVA ACURÁCIAS E PARAMETROS\n",
    "dump_info = {\n",
    "    'method': 'Grid Search Random Forest',\n",
    "    'seed': random_state,\n",
    "    'feature_method': method_algo,\n",
    "    'sample_rate': sampling_rate,\n",
    "    'train_test': [len(X_train), len(X_valid), len(X_test)],\n",
    "    'score_train': score_train,\n",
    "    'score_valid': score_valid,\n",
    "    'score_test': score_test,\n",
    "    'f1_micro': f1_score(y_hat, y_test, average='micro'),\n",
    "    'f1_macro': f1_score(y_hat, y_test, average='macro'),\n",
    "    'model_file': f'acc{score_test}_seed{random_state}.sav',\n",
    "    'params': model.best_params_,\n",
    "    'cv_results': model.cv_results_\n",
    "}\n",
    "\n",
    "JSON.create_json_file(f'models/gridperceptron/{method_algo}_{f1_score(y_hat, y_test, average=\"macro\")}_{sampling_rate}/info.json', dump_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVA A ESTRUTURA DO MODELO\n",
    "\n",
    "# timestamp = int(time.time())\n",
    "\n",
    "# Directory.create_directory(f'models/{model_algo}/{method_algo}/{timestamp}')\n",
    "\n",
    "# JSON.create_json_file(f'models/{model_algo}/{method_algo}/{timestamp}/model_structure.json', model.to_json())\n",
    "\n",
    "# model_save_filename = f'models/{model_algo}/{method_algo}/{timestamp}/model_weight.h5'\n",
    "\n",
    "# # DECIDE QUANDO PARAR\n",
    "# earlystopping_cb = keras.callbacks.EarlyStopping(patience=300, restore_best_weights=True)\n",
    "\n",
    "# # SALVA OS PESOS\n",
    "# mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "# model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINA O MODELO\n",
    "# history = model.fit(inputs_train, targets_train,\n",
    "#             validation_data=(inputs_valid, targets_valid),\n",
    "#             epochs=10000,\n",
    "#             batch_size=128,\n",
    "#             callbacks=[earlystopping_cb, mdlcheckpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GERA O GRAFICO DE ACURÁCIA\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(f'models/{model_algo}/{method_algo}/{timestamp}/graph_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# GERA O GRÁFICO DE PERCA\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(f'models/{model_algo}/{method_algo}/{timestamp}/graph_loss.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEGA A MAIOR E ACURÁCIA\n",
    "higher_accuracy = model.evaluate(inputs_test, targets_test, batch_size=128)\n",
    "\n",
    "higher_accuracy = str(int(higher_accuracy[1] * 10000)).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENOMEIA A PASTA\n",
    "Directory.rename_directory(f'models/{model_algo}/{method_algo}/{timestamp}',\n",
    "                   f'models/{model_algo}/{method_algo}/acc{higher_accuracy}_seed{random_state}_epochs{len(history.history[\"accuracy\"])}_time{timestamp}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {},
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}